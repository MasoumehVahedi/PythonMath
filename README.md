# Math Skills using Python and Numpy

A concise reference of the core mathematical ideas & NumPy idioms for Machine Learning algorithms. Each topic is distilled to what you need to remember.

## 1- Linear Algebra & Matrix Operations (heavy emphasis on NumPy):

### - Vector/Matrix Manipulations: Dot products, matrix multiplication, transposes, inverses, determinants.

### - Eigenvalues/Eigenvectors: related to PCA or spectral clustering.

### - Solving Linear Systems: Using NumPy's linear algebra capabilities.

### - Norms and Distances: L1, L2 norms, cosine similarity.

## 2- Probability and Statistics:

### - Basic Probability: Conditional probability, Bayes' theorem.

### - Statistical Distributions: Normal, binomial, etc. (understanding their properties and how to sample/use them).

### - Descriptive Statistics: Mean, median, variance, standard deviation.

### - Hypothesis Testing: P‑values, confidence intervals.

## 3- Optimization:

### - Gradient Descent: Understanding the concept, perhaps even a simplified implementation of a single step or a basic version. 

### - Loss Functions: Understanding common loss functions used in machine learning (e.g., Mean Squared Error, Cross‑Entropy).

## 4- Mathematical Foundations of Machine Learning/Deep Learning:

### - Activation Functions: Sigmoid, ReLU, tanh (understanding their mathematical definitions).

### - Softmax: A crucial function for multi‑class classification.

### - Information Theory: Entropy, cross‑entropy, KL divergence.

## 5- Basic Algorithms/Data Structures (but often with a numerical twist):

### - Operations on arrays/lists that mimic vector/matrix operations.

### - Efficient calculations.
